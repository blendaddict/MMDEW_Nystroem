{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-20T08:00:08.953019Z",
     "start_time": "2023-08-20T08:00:08.942546Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmdew.bucket_stream2 import BucketStream\n",
    "from mmdew.bucket_stream_old import BucketStream as OldBucketStream\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mmdew.mmd import MMD\n",
    "from sklearn import metrics\n",
    "import numpy.linalg as la\n",
    "from mmdew.bucket_stream2 import Bucket\n",
    "import  math\n",
    "\n",
    "def mmd(split, buckets, k):\n",
    "    start = buckets[:split]\n",
    "    end = buckets[split:]\n",
    "    #breakpoint()\n",
    "    start_elements = start[0].elements\n",
    "    start_weights = start[0].weights * start[0].uncompressed_capacity\n",
    "    end_elements = end[0].elements\n",
    "    end_weights = end[0].weights * end[0].uncompressed_capacity\n",
    "    start_uncompressed_capacity = start[0].uncompressed_capacity\n",
    "    end_uncompressed_capacity = end[0].uncompressed_capacity\n",
    "    #breakpoint()\n",
    "    for bucket in start[1:]:\n",
    "        #breakpoint()\n",
    "        start_elements = np.concatenate((start_elements, bucket.elements))\n",
    "        start_weights = np.concatenate((start_weights, bucket.weights * bucket.uncompressed_capacity))\n",
    "        start_uncompressed_capacity += bucket.uncompressed_capacity\n",
    "    for bucket in end[1:]:\n",
    "        #breakpoint()\n",
    "        end_elements = np.concatenate((end_elements, bucket.elements))\n",
    "        #breakpoint()\n",
    "        end_weights = np.concatenate((end_weights, bucket.weights * bucket.uncompressed_capacity))\n",
    "        end_uncompressed_capacity += bucket.uncompressed_capacity\n",
    "    #\n",
    "\n",
    "    start_capacity = len(start_elements)\n",
    "    end_capacity = len(end_elements)\n",
    "    start_weights = start_weights * (1/start_uncompressed_capacity)\n",
    "    end_weights = end_weights * (1/end_uncompressed_capacity)\n",
    "    #breakpoint()\n",
    "    addend_1 = start_weights.T @ k(start_elements, start_elements) @ start_weights\n",
    "    addend_2 = end_weights.T @ k(end_elements, end_elements) @ end_weights\n",
    "    addend_3 = start_weights.T @ k(start_elements, end_elements) @ end_weights\n",
    "    return (addend_1 + addend_2 - (2 * addend_3))[0][0], start_uncompressed_capacity, end_uncompressed_capacity\n",
    "\n",
    "def merge_buckets_with_subsampling(bucket_list,k, apply_subsampling):\n",
    "    \"\"\"Merges the buckets in `bucket_list` such that one bucket remains with XX, and XY such that their values correspond to the case that all data would have been in this bucket.\"\"\"\n",
    "    if len(bucket_list) == 1:\n",
    "        return bucket_list[0]\n",
    "    current = bucket_list[-1]\n",
    "    previous = bucket_list[-2]\n",
    "\n",
    "    current_elements = current.elements\n",
    "    previous_elements = previous.elements\n",
    "    current_weights = current.weights\n",
    "    previous_weights = previous.weights\n",
    "\n",
    "    joined_elements = np.concatenate((current_elements, previous_elements))\n",
    "    joined_uncompressed_capacity = current.uncompressed_capacity + previous.uncompressed_capacity\n",
    "    #subsampling seems to be too extreme. Maybe select less aggressively\n",
    "    #maybe choose combined uncompressed capacity as n which would probably not contradict the chatalic paper\n",
    "    #breakpoint()\n",
    "    if joined_uncompressed_capacity > 16:\n",
    "\n",
    "        m = round(math.sqrt(joined_uncompressed_capacity))  # size of the subsample\n",
    "        #ToDo: uncomment this\n",
    "        #m_idx = np.random.default_rng().integers(len(joined_elements), size=m)\n",
    "        m_idx = range(0,m)\n",
    "        subsample = joined_elements[m_idx]\n",
    "    else:\n",
    "        m = joined_uncompressed_capacity\n",
    "        subsample = joined_elements\n",
    "   # assuming current_elements and previous_elements have the same length\n",
    "\n",
    "\n",
    "    joined_weights = np.concatenate((current_weights, previous_weights))\n",
    "    #breakpoint()\n",
    "    K_z = k(subsample, joined_elements)\n",
    "\n",
    "\n",
    "\n",
    "    #K_m = np.zeros((m, m))  # initialize the kernel matrix with zeros\n",
    "    #for i in range(m):\n",
    "        #for j in range(m):\n",
    "            # reshape to 2D array as rbf_kernel expects 2D array\n",
    "\n",
    "    K_m = k(subsample, subsample)\n",
    "    K_m_inv = la.pinv(K_m)\n",
    "    #breakpoint()\n",
    "    new_weights = .5 * K_m_inv @ K_z @ joined_weights\n",
    "    return merge_buckets_with_subsampling(\n",
    "        bucket_list[:-2]\n",
    "        + [\n",
    "            Bucket(\n",
    "                elements=subsample,\n",
    "                weights=new_weights,\n",
    "                capacity=m,\n",
    "                uncompressed_capacity=joined_uncompressed_capacity\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def merge(buckets,k):\n",
    "    if len(buckets) < 2:\n",
    "        return buckets\n",
    "    current = buckets[-1]\n",
    "    previous = buckets[-2]\n",
    "    if previous.uncompressed_capacity == current.uncompressed_capacity:\n",
    "        buckets = buckets[:-2] + [merge_buckets_with_subsampling(buckets[-2:],k)]\n",
    "        buckets = merge(buckets)\n",
    "    return buckets\n",
    "\n",
    "\n",
    "def insert_no_cut(buckets, element,k):\n",
    "    #breaxkpoint()\n",
    "    buckets += [\n",
    "        Bucket(\n",
    "            elements=np.array(element).reshape(1,-1),\n",
    "            weights=np.array(1).reshape(1,-1),\n",
    "            capacity=1,\n",
    "            uncompressed_capacity=1\n",
    "        )\n",
    "    ]\n",
    "    return merge(buckets,k)\n",
    "\n",
    "    #breakpoint()\n",
    "\n",
    "def run_new_test(rbf_kernel=False, random_data = False, limit=64, apply_subsampling=True, sample_random=False, even_sized=False):\n",
    "    if random_data:\n",
    "        X = np.random.normal(0, 1, limit)\n",
    "        Y = np.random.normal(1, 2, limit)\n",
    "    else:\n",
    "        X = np.repeat([[1,2,3]], limit, axis=0)\n",
    "        Y = np.repeat([[4,5,6]], limit, axis=0)\n",
    "    bs = []\n",
    "    if rbf_kernel:\n",
    "        k = lambda X, Y: metrics.pairwise.rbf_kernel(X,Y,1)\n",
    "    else:\n",
    "        k = lambda X, Y: metrics.pairwise.distance_metrics(X,Y)\n",
    "    for i in range(0,128):\n",
    "        bs = insert_no_cut(bs, X[i],k)\n",
    "    for i in range(0,127):\n",
    "        bs = insert_no_cut(bs, Y[i],k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
