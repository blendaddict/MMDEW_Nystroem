{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Let's try to compare the mmd of the 2 distributions to one nyström subsampled bucked for X and one not subsampled bucket for Y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real mmd:0.6016100063216595\n",
      "nyström mmd: 0.6016100063216595\n"
     ]
    }
   ],
   "source": [
    "from mmdew.bucket_stream2 import BucketStream\n",
    "from mmdew.bucket_stream_old import BucketStream as OldBucketStream\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mmdew.mmd import MMD\n",
    "mymmd = MMD(biased=True, gamma=1)\n",
    "from sklearn import metrics\n",
    "import numpy.linalg as la\n",
    "np.random.seed(40)\n",
    "X = np.random.normal(0, 1, 32)\n",
    "Y = np.random.normal(1, 2, 32)\n",
    "\n",
    "\n",
    "m_idx = np.random.default_rng().integers(32, size=5)\n",
    "subsample = X[m_idx]\n",
    "start_weights = ((1/32) * la.pinv(metrics.pairwise.linear_kernel(subsample.reshape(-1,1),subsample.reshape(-1,1)))\n",
    "                 @ metrics.pairwise.linear_kernel(subsample.reshape(-1,1),X.reshape(-1,1)) @ np.ones(32))\n",
    "\n",
    "\n",
    "\n",
    "end_weights = np.ones((32,1))/32\n",
    "addend_1 = start_weights.T @ metrics.pairwise.linear_kernel(subsample.reshape(-1,1), subsample.reshape(-1,1)) @ start_weights\n",
    "addend_2 = end_weights.T @ metrics.pairwise.linear_kernel(Y.reshape(-1,1), Y.reshape(-1,1)) @ end_weights\n",
    "addend_3 = start_weights.T @ metrics.pairwise.linear_kernel(subsample.reshape(-1,1), Y.reshape(-1,1)) @ end_weights\n",
    "print(f\"real mmd:{mymmd.mmd(X.reshape(-1,1),Y.reshape(-1,1))}\")\n",
    "print(f\"nyström mmd: {(addend_1 + addend_2 - (2 * addend_3))[0][0]}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:29.573362361Z",
     "start_time": "2023-08-15T13:35:29.540599266Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MMD is identical\n",
    "now let's try to create 2 subsampled buckets from X, merge them into a third bucket with the elements: new_subsample and the weights: new_weights, then check MMD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real mmd:2.3226094951499947\n",
      "nyström mmd of bucket, made of subsampled buckets: 2.3226094951499943\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "X_1 = np.random.normal(0, 1, 32)\n",
    "X_2 = np.random.normal(0, 1, 32)\n",
    "Y = np.random.normal(1, 2, 64)\n",
    "\n",
    "\n",
    "m_idx1 = np.random.default_rng().integers(32, size=5)\n",
    "subsample1 = X_1[m_idx1]\n",
    "m_idx2 = np.random.default_rng().integers(32, size=5)\n",
    "subsample2 = X_2[m_idx1]\n",
    "bucket1_weights = ((1/32) * la.pinv(metrics.pairwise.linear_kernel(subsample1.reshape(-1,1),subsample1.reshape(-1,1)))\n",
    "                 @ metrics.pairwise.linear_kernel(subsample1.reshape(-1,1),X_1.reshape(-1,1)) @ np.ones(32))\n",
    "bucket2_weights = ((1/32) * la.pinv(metrics.pairwise.linear_kernel(subsample2.reshape(-1,1),subsample2.reshape(-1,1)))\n",
    "                 @ metrics.pairwise.linear_kernel(subsample2.reshape(-1,1),X_2.reshape(-1,1)) @ np.ones(32))\n",
    "\n",
    "#getting new elements\n",
    "joined_subsamples = np.concatenate((subsample1, subsample2))\n",
    "joined_uncompressed_capacity = 64\n",
    "m = round(math.sqrt(64))\n",
    "m_idx_new = np.random.default_rng().integers(len(joined_subsamples), size=m)\n",
    "new_subsample = joined_subsamples[m_idx_new]\n",
    "\n",
    "#getting new weights\n",
    "new_subsample = new_subsample.reshape(-1,1)\n",
    "joined_subsamples = joined_subsamples.reshape(-1,1)\n",
    "joined_weights = np.concatenate((bucket1_weights,bucket2_weights))\n",
    "K_z = metrics.pairwise.linear_kernel(new_subsample, joined_subsamples)\n",
    "K_m_inv = la.pinv(metrics.pairwise.linear_kernel(new_subsample, new_subsample))\n",
    "new_weights = .5 * K_m_inv @ K_z @ joined_weights\n",
    "\n",
    "#weights for Y\n",
    "end_weights = np.ones((64,1))/64\n",
    "\n",
    "addend_1 = new_weights.T @ metrics.pairwise.linear_kernel(new_subsample.reshape(-1,1), new_subsample.reshape(-1,1)) @ new_weights\n",
    "addend_2 = end_weights.T @ metrics.pairwise.linear_kernel(Y.reshape(-1,1), Y.reshape(-1,1)) @ end_weights\n",
    "addend_3 = new_weights.T @ metrics.pairwise.linear_kernel(new_subsample.reshape(-1,1), Y.reshape(-1,1)) @ end_weights\n",
    "\n",
    "print(f\"real mmd:{mymmd.mmd(np.concatenate((X_1,X_2)).reshape(-1,1),Y.reshape(-1,1))}\")\n",
    "print(f\"nyström mmd of bucket, made of subsampled buckets: {(addend_1 + addend_2 - (2 * addend_3))[0][0]}\")\n",
    "breakpoint()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:29.712563417Z",
     "start_time": "2023-08-15T13:35:29.554401533Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MMD is equal \n",
    "why does this not work in bucketstream2.py ? "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for exponent 1 is 6.938893903907228e-16\n",
      "error for exponent 2 is 1.2212453270876722e-15\n",
      "error for exponent 3 is 1.2212453270876722e-15\n",
      "error for exponent 4 is 6.161737786669619e-16\n",
      "error for exponent 5 is 7.93809462606987e-16\n",
      "error for exponent 6 is 0.27322697803554885\n",
      "error for exponent 7 is 0.29218514919762306\n",
      "error for exponent 8 is 0.2324963532574406\n",
      "error for exponent 9 is 0.2465660856119707\n",
      "error for exponent 10 is 0.1989622980445256\n"
     ]
    }
   ],
   "source": [
    "from mmdew.bucket_stream2 import BucketStream\n",
    "from mmdew.bucket_stream_old import BucketStream as OldBucketStream\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mmdew.mmd import MMD\n",
    "mymmd = MMD(biased=True, gamma=1)\n",
    "if __name__ == \"__main__\":\n",
    "    bs_ss = BucketStream(gamma=1)\n",
    "    bs_no_ss = BucketStream(gamma=1, apply_subsampling=False)\n",
    "    bs_old = OldBucketStream(gamma=1)\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    for exponent in range(1, 11):\n",
    "        iter_errors = []\n",
    "        for iteration in range(1,11):\n",
    "\n",
    "            bs_ss = BucketStream(gamma=1)\n",
    "            bs_no_ss = BucketStream(gamma=1, apply_subsampling=False)\n",
    "            bs_old = OldBucketStream(gamma=1)\n",
    "            limit = 2 ** exponent\n",
    "            X = np.random.normal(0, 1, limit)\n",
    "            Y = np.random.normal(1, 2, limit - 1)\n",
    "           \n",
    "            for i in range(0, limit):\n",
    "                bs_ss.insert_no_cut(X[i])\n",
    "             \n",
    "            for i in range(0, limit - 1):\n",
    "                bs_ss.insert_no_cut(Y[i])\n",
    "      \n",
    "            ss_mmd = bs_ss.mmd(1)[0]\n",
    "            real_mmd = mymmd.mmd(X.reshape(-1, 1),Y.reshape(-1, 1))\n",
    "            #print(f\"SS:    exponent: {exponent} bucket count: {len(bs_ss.buckets)} mmd value={ss_mmd}\")\n",
    "         \n",
    "            #print(f\"real MMD: {real_mmd}\")\n",
    "            iter_errors = np.concatenate(( iter_errors, [(abs(real_mmd - ss_mmd))]))\n",
    "            #if iteration == 1 and exponent == 5 :\n",
    "            #    breakpoint()\n",
    "        errors = np.concatenate((errors, [np.array(iter_errors).mean()] ))\n",
    "\n",
    "    for i in range(0,10):\n",
    "        print(f\"error for exponent {i+1} is {errors[i]}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:34.910187695Z",
     "start_time": "2023-08-15T13:35:29.596412617Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exponent 6 is the first time that we subsample with depth > 1 \n",
    "But we just showed that this isn't the problem. Let's have a deeper look"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SS:    exponent: 6 bucket count: 7 mmd value=0.3138935548362058\n",
      "real MMD: 0.16034832195908985\n",
      "\n",
      "Element count: 8\n",
      "Elems:\t[[-0.61609615]\n",
      " [-0.58468393]\n",
      " [-0.60527542]\n",
      " [ 1.30946385]\n",
      " [ 0.46623726]\n",
      " [-0.11185297]\n",
      " [-0.50221412]\n",
      " [-0.90660695]]\n",
      "Weights:\t[[-0.00683258]\n",
      " [-0.00648422]\n",
      " [-0.00671258]\n",
      " [ 0.01452212]\n",
      " [ 0.00517063]\n",
      " [-0.00124046]\n",
      " [-0.00556962]\n",
      " [-0.01005438]]\n",
      "Uncomp_Cap:\t64\n",
      "\n",
      "\n",
      "Element count: 6\n",
      "Elems:\t[[-5.16731105]\n",
      " [ 1.442592  ]\n",
      " [ 0.80318161]\n",
      " [-1.25148157]\n",
      " [-0.55198791]\n",
      " [ 1.65023783]]\n",
      "Weights:\t[[-0.03319136]\n",
      " [ 0.00926625]\n",
      " [ 0.0051591 ]\n",
      " [-0.00803868]\n",
      " [-0.0035456 ]\n",
      " [ 0.01060003]]\n",
      "Uncomp_Cap:\t32\n",
      "\n",
      "\n",
      "Element count: 16\n",
      "Elems:\t[[ 3.96456395]\n",
      " [-3.91575867]\n",
      " [ 5.60934544]\n",
      " [-0.15462216]\n",
      " [ 4.089723  ]\n",
      " [-2.63150713]\n",
      " [ 0.51620667]\n",
      " [ 0.76058081]\n",
      " [ 0.70668094]\n",
      " [ 0.30310334]\n",
      " [ 1.38158431]\n",
      " [-1.10191109]\n",
      " [-0.56608032]\n",
      " [-0.83511113]\n",
      " [ 2.38796535]\n",
      " [ 1.58207457]]\n",
      "Weights:\t[[ 0.02998238]\n",
      " [-0.02961328]\n",
      " [ 0.04242119]\n",
      " [-0.00116934]\n",
      " [ 0.0309289 ]\n",
      " [-0.01990101]\n",
      " [ 0.00390386]\n",
      " [ 0.00575196]\n",
      " [ 0.00534434]\n",
      " [ 0.00229225]\n",
      " [ 0.01044836]\n",
      " [-0.0083333 ]\n",
      " [-0.00428103]\n",
      " [-0.0063156 ]\n",
      " [ 0.01805921]\n",
      " [ 0.01196458]]\n",
      "Uncomp_Cap:\t16\n",
      "\n",
      "\n",
      "Element count: 8\n",
      "Elems:\t[[-0.09400089]\n",
      " [-0.68859287]\n",
      " [ 3.60973353]\n",
      " [-0.74540272]\n",
      " [ 5.15925661]\n",
      " [ 2.14174735]\n",
      " [-2.01334251]\n",
      " [ 0.01236813]]\n",
      "Weights:\t[[-0.00175838]\n",
      " [-0.01288082]\n",
      " [ 0.06752371]\n",
      " [-0.01394351]\n",
      " [ 0.0965091 ]\n",
      " [ 0.04006355]\n",
      " [-0.0376616 ]\n",
      " [ 0.00023136]]\n",
      "Uncomp_Cap:\t8\n",
      "\n",
      "\n",
      "Element count: 4\n",
      "Elems:\t[[-2.88840637]\n",
      " [-0.22055588]\n",
      " [ 2.1954517 ]\n",
      " [ 3.17952565]]\n",
      "Weights:\t[[-0.07016415]\n",
      " [-0.00535767]\n",
      " [ 0.05333114]\n",
      " [ 0.07723592]]\n",
      "Uncomp_Cap:\t4\n",
      "\n",
      "\n",
      "Element count: 2\n",
      "Elems:\t[[1.90002629]\n",
      " [1.13966656]]\n",
      "Weights:\t[[0.58826311]\n",
      " [0.35284974]]\n",
      "Uncomp_Cap:\t2\n",
      "\n",
      "\n",
      "Element count: 1\n",
      "Elems:\t[[-3.68075336]]\n",
      "Weights:\t[[1]]\n",
      "Uncomp_Cap:\t1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bs_ss = BucketStream(gamma=1)\n",
    "exponent = 6\n",
    "limit = 2 ** exponent\n",
    "X = np.random.normal(0, 1, limit)\n",
    "Y = np.random.normal(1, 2, limit - 1)\n",
    "\n",
    "for i in range(0, limit):\n",
    "    bs_ss.insert_no_cut(X[i])\n",
    " \n",
    "for i in range(0, limit - 1):\n",
    "    bs_ss.insert_no_cut(Y[i])\n",
    "\n",
    "ss_mmd = bs_ss.mmd(1)[0]\n",
    "real_mmd = mymmd.mmd(X.reshape(-1, 1),Y.reshape(-1, 1))\n",
    "print(f\"SS:    exponent: {exponent} bucket count: {len(bs_ss.buckets)} mmd value={ss_mmd}\")\n",
    "print(f\"real MMD: {real_mmd}\\n\")\n",
    "for bucket in bs_ss.buckets:\n",
    "    print(f\"Element count: {len(bucket.elements)}\" )\n",
    "    print(bucket)\n",
    "    print(\"\\n\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:34.956462746Z",
     "start_time": "2023-08-15T13:35:34.913223060Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## This does not look to bad. (Except for the mmd disparity of course)\n",
    "The amount of subsamples is right. the weight count matches...\n",
    "Let's try to reconstruct the mmd calc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "8\n",
      "63\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "start = bs_ss.buckets[:1]\n",
    "end = bs_ss.buckets[1:]\n",
    "start_elements = start[0].elements\n",
    "start_weights = start[0].weights * len(start[0].weights)\n",
    "end_elements = end[0].elements\n",
    "end_weights = end[0].weights * len(end[0].weights)\n",
    "start_uncompressed_capacity = start[0].uncompressed_capacity\n",
    "end_uncompressed_capacity = end[0].uncompressed_capacity\n",
    "for bucket in start[1:]:\n",
    "    #breakpoint()\n",
    "    start_elements = np.concatenate((start_elements, bucket.elements))\n",
    "    start_weights = np.concatenate((start_weights, bucket.weights * len(bucket.weights)))\n",
    "    start_uncompressed_capacity += bucket.uncompressed_capacity\n",
    "for bucket in end[1:]:\n",
    "    #breakpoint()\n",
    "    end_elements = np.concatenate((end_elements, bucket.elements))\n",
    "    #breakpoint()\n",
    "    end_weights = np.concatenate((end_weights, bucket.weights * len(bucket.weights)))\n",
    "    end_uncompressed_capacity += bucket.uncompressed_capacity\n",
    "start_capacity = len(start_elements)\n",
    "end_capacity = len(end_elements)\n",
    "print(start_uncompressed_capacity)\n",
    "print(start_capacity)\n",
    "print(end_uncompressed_capacity)\n",
    "print(end_capacity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.031814494Z",
     "start_time": "2023-08-15T13:35:34.938509469Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Yes, everything seems to be alright\n",
    "37 is exactly the amount of samples that should be right of the split because of: 31 elements from the buckets without subsampling and 5 (+1 for bad rounding) from the subsampled u-cap 32 bucket\n",
    "## Let's look deeper..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Weights\n",
      "[[-0.00683258]\n",
      " [-0.00648422]\n",
      " [-0.00671258]\n",
      " [ 0.01452212]\n",
      " [ 0.00517063]\n",
      " [-0.00124046]\n",
      " [-0.00556962]\n",
      " [-0.01005438]]\n",
      "\n",
      "End Weights\n",
      "[[-5.38238211e-03]\n",
      " [ 1.50263479e-03]\n",
      " [ 8.36611207e-04]\n",
      " [-1.30357007e-03]\n",
      " [-5.74962452e-04]\n",
      " [ 1.71892314e-03]\n",
      " [ 1.29653518e-02]\n",
      " [-1.28057434e-02]\n",
      " [ 1.83442965e-02]\n",
      " [-5.05662354e-04]\n",
      " [ 1.33746606e-02]\n",
      " [-8.60584316e-03]\n",
      " [ 1.68815566e-03]\n",
      " [ 2.48733477e-03]\n",
      " [ 2.31106551e-03]\n",
      " [ 9.91241769e-04]\n",
      " [ 4.51820852e-03]\n",
      " [-3.60359049e-03]\n",
      " [-1.85125793e-03]\n",
      " [-2.73107198e-03]\n",
      " [ 7.80938613e-03]\n",
      " [ 5.17387376e-03]\n",
      " [-3.80190578e-04]\n",
      " [-2.78504311e-03]\n",
      " [ 1.45997206e-02]\n",
      " [-3.01481298e-03]\n",
      " [ 2.08668325e-02]\n",
      " [ 8.66238811e-03]\n",
      " [-8.14304931e-03]\n",
      " [ 5.00234369e-05]\n",
      " [-7.58531371e-03]\n",
      " [-5.79207111e-04]\n",
      " [ 5.76552872e-03]\n",
      " [ 8.34982908e-03]\n",
      " [ 3.17980058e-02]\n",
      " [ 1.90729591e-02]\n",
      " [ 2.70270270e-02]]\n"
     ]
    }
   ],
   "source": [
    "start_weights = start_weights * (1/start_capacity)\n",
    "end_weights = end_weights * (1/end_capacity)\n",
    "#breakpoint()\n",
    "print(\"Start Weights\")\n",
    "print(start_weights)\n",
    "print(\"\\nEnd Weights\")\n",
    "print(end_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.032148018Z",
     "start_time": "2023-08-15T13:35:34.980470433Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00207406]]\n",
      "[[0.36699842]]\n",
      "[[0.02758946]]\n",
      "[[0.31389355]]\n"
     ]
    }
   ],
   "source": [
    "addend_1 = start_weights.T @ metrics.pairwise.linear_kernel(start_elements, start_elements) @ start_weights\n",
    "addend_2 = end_weights.T @ metrics.pairwise.linear_kernel(end_elements, end_elements) @ end_weights\n",
    "addend_3 = start_weights.T @ metrics.pairwise.linear_kernel(start_elements, end_elements) @ end_weights\n",
    "print(addend_1)\n",
    "print(addend_2)\n",
    "print(addend_3)\n",
    "print(addend_1+addend_2-(2*addend_3))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.032422569Z",
     "start_time": "2023-08-15T13:35:34.980652311Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ok let's start over"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "from mmdew.bucket_stream2 import Bucket\n",
    "\n",
    "def k( x, y):\n",
    "\n",
    "    #return metrics.pairwise.rbf_kernel(x,y, gamma=self.gamma)\n",
    "    return metrics.pairwise.linear_kernel(x,y)\n",
    "\n",
    "\n",
    "def mmd(split, buckets):\n",
    "    start = buckets[:split]\n",
    "    end = buckets[split:]\n",
    "    #breakpoint()\n",
    "    start_elements = start[0].elements\n",
    "    start_weights = start[0].weights * start[0].uncompressed_capacity\n",
    "    end_elements = end[0].elements\n",
    "    end_weights = end[0].weights * end[0].uncompressed_capacity\n",
    "    start_uncompressed_capacity = start[0].uncompressed_capacity\n",
    "    end_uncompressed_capacity = end[0].uncompressed_capacity\n",
    "    #breakpoint()\n",
    "    for bucket in start[1:]:\n",
    "        #breakpoint()\n",
    "        start_elements = np.concatenate((start_elements, bucket.elements))\n",
    "        start_weights = np.concatenate((start_weights, bucket.weights * bucket.uncompressed_capacity))\n",
    "        start_uncompressed_capacity += bucket.uncompressed_capacity\n",
    "    for bucket in end[1:]:\n",
    "        #breakpoint()\n",
    "        end_elements = np.concatenate((end_elements, bucket.elements))\n",
    "        #breakpoint()\n",
    "        end_weights = np.concatenate((end_weights, bucket.weights * bucket.uncompressed_capacity))\n",
    "        end_uncompressed_capacity += bucket.uncompressed_capacity\n",
    "    #\n",
    "\n",
    "    start_capacity = len(start_elements)\n",
    "    end_capacity = len(end_elements)\n",
    "    start_weights = start_weights * (1/start_uncompressed_capacity)\n",
    "    end_weights = end_weights * (1/end_uncompressed_capacity)\n",
    "    #breakpoint()\n",
    "    addend_1 = start_weights.T @ k(start_elements, start_elements) @ start_weights\n",
    "    addend_2 = end_weights.T @ k(end_elements, end_elements) @ end_weights\n",
    "    addend_3 = start_weights.T @ k(start_elements, end_elements) @ end_weights\n",
    "    return (addend_1 + addend_2 - (2 * addend_3))[0][0], start_uncompressed_capacity, end_uncompressed_capacity\n",
    "def merge_buckets_with_subsampling(bucket_list):\n",
    "    \"\"\"Merges the buckets in `bucket_list` such that one bucket remains with XX, and XY such that their values correspond to the case that all data would have been in this bucket.\"\"\"\n",
    "    if len(bucket_list) == 1:\n",
    "        return bucket_list[0]\n",
    "    current = bucket_list[-1]\n",
    "    previous = bucket_list[-2]\n",
    "\n",
    "    current_elements = current.elements\n",
    "    previous_elements = previous.elements\n",
    "    current_weights = current.weights\n",
    "    previous_weights = previous.weights\n",
    "\n",
    "    joined_elements = np.concatenate((current_elements, previous_elements))\n",
    "    joined_uncompressed_capacity = current.uncompressed_capacity + previous.uncompressed_capacity\n",
    "    #subsampling seems to be too extreme. Maybe select less aggressively\n",
    "    #maybe choose combined uncompressed capacity as n which would probably not contradict the chatalic paper\n",
    "    #breakpoint()\n",
    "    if joined_uncompressed_capacity > 16:\n",
    "\n",
    "        m = round(math.sqrt(joined_uncompressed_capacity))  # size of the subsample\n",
    "        #ToDo: uncomment this\n",
    "        #m_idx = np.random.default_rng().integers(len(joined_elements), size=m)\n",
    "        m_idx = range(0,m)\n",
    "        subsample = joined_elements[m_idx]\n",
    "    else:\n",
    "        m = joined_uncompressed_capacity\n",
    "        subsample = joined_elements\n",
    "   # assuming current_elements and previous_elements have the same length\n",
    "\n",
    "\n",
    "    joined_weights = np.concatenate((current_weights, previous_weights))\n",
    "    #breakpoint()\n",
    "    K_z = k(subsample, joined_elements)\n",
    "\n",
    "\n",
    "\n",
    "    #K_m = np.zeros((m, m))  # initialize the kernel matrix with zeros\n",
    "    #for i in range(m):\n",
    "        #for j in range(m):\n",
    "            # reshape to 2D array as rbf_kernel expects 2D array\n",
    "\n",
    "    K_m = k(subsample, subsample)\n",
    "    K_m_inv = la.pinv(K_m)\n",
    "    #breakpoint()\n",
    "    new_weights = .5 * K_m_inv @ K_z @ joined_weights\n",
    "    return merge_buckets_with_subsampling(\n",
    "        bucket_list[:-2]\n",
    "        + [\n",
    "            Bucket(\n",
    "                elements=subsample,\n",
    "                weights=new_weights,\n",
    "                capacity=m,\n",
    "                uncompressed_capacity=joined_uncompressed_capacity\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    #print(f\"split: {split} start_uncompressed_capacity: {start_uncompressed_capacity} und end_uncompressed_capacity: {end_uncompressed_capacity}\")\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.032556964Z",
     "start_time": "2023-08-15T13:35:34.980770045Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "X = np.random.normal(0, 1, 128)\n",
    "Y = np.random.normal(1, 2, 127)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.034201822Z",
     "start_time": "2023-08-15T13:35:34.980942543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.034379949Z",
     "start_time": "2023-08-15T13:35:35.024392869Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "bs = []\n",
    "def insert_no_cut(buckets, element):\n",
    "    #breakpoint()\n",
    "    buckets += [\n",
    "        Bucket(\n",
    "            elements=np.array(element).reshape(1,-1),\n",
    "            weights=np.array(1).reshape(1,-1),\n",
    "            capacity=1,\n",
    "            uncompressed_capacity=1\n",
    "        )\n",
    "    ]\n",
    "    return merge(buckets)\n",
    "    \n",
    "    #breakpoint()\n",
    "    \n",
    "def merge(buckets):\n",
    "    if len(buckets) < 2:\n",
    "        return buckets\n",
    "    current = buckets[-1]\n",
    "    previous = buckets[-2]\n",
    "    if previous.uncompressed_capacity == current.uncompressed_capacity:\n",
    "        buckets = buckets[:-2] + [merge_buckets_with_subsampling(buckets[-2:])]\n",
    "        buckets = merge(buckets)\n",
    "    return buckets\n",
    "\n",
    "for i in range(0,128):\n",
    "    bs = insert_no_cut(bs, X[i])\n",
    "for i in range(0,127):\n",
    "    bs = insert_no_cut(bs, Y[i])\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.083663366Z",
     "start_time": "2023-08-15T13:35:35.024561946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elems:\t[[ 3.00111581]\n",
      " [ 4.52203497]\n",
      " [-1.25229966]\n",
      " [ 0.21688528]\n",
      " [ 2.59023479]\n",
      " [ 2.75207267]\n",
      " [ 0.62721281]\n",
      " [-0.48475151]]\n",
      "Weights:\t[[ 0.08257456]\n",
      " [ 0.12442208]\n",
      " [-0.03445655]\n",
      " [ 0.00596752]\n",
      " [ 0.07126933]\n",
      " [ 0.07572224]\n",
      " [ 0.01725752]\n",
      " [-0.01333775]]\n",
      "Uncomp_Cap:\t64\n"
     ]
    }
   ],
   "source": [
    "print(bs[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.109818761Z",
     "start_time": "2023-08-15T13:35:35.059146728Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "data": {
      "text/plain": "(1.1663497414336537, 128, 127)"
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd(1,bs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.110226478Z",
     "start_time": "2023-08-15T13:35:35.100416534Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "1.166349741433654"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymmd.mmd(X.reshape(-1,1),Y.reshape(-1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T13:35:35.110505739Z",
     "start_time": "2023-08-15T13:35:35.100584691Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
